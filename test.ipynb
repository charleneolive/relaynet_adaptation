{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "attended-afghanistan",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "activated-protein",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import scipy\n",
    "import scipy.io\n",
    "import cv2\n",
    "import sys\n",
    "import h5py\n",
    "import yaml\n",
    "import sklearn\n",
    "import warnings\n",
    "import json\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import sklearn.metrics\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from preprocess.data_prep_utils import octSpectralisReader as rd\n",
    "from preprocess.data_prep_utils.misc import build_mask\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable \n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "outdoor-firewall",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open( \"./test.yaml\") as file:\n",
    "    config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "filepaths = config['filepaths']\n",
    "test_dataset_list = os.path.join(filepaths['project_dir'],'data','processed', filepaths['dataset_name'], filepaths['test_dataset'])\n",
    "dimensions = config['general']\n",
    "layers = config['layers']\n",
    "\n",
    "relaynet_model =  torch.load(filepaths['model_path'])\n",
    "relaynet_model.eval()\n",
    "\n",
    "all_test_cases = []\n",
    "with open(test_dataset_list,'r') as reader:\n",
    "    for idx, line in enumerate(reader.readlines()):\n",
    "        all_test_cases.append(line.strip('\\n'))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45628afa-ee8e-4d08-b83d-a1478046799a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvalPatient:\n",
    "    def __init__(self, patient, dimensions, dataset_name, layers, save_path):\n",
    "        self.patient = patient\n",
    "        self.dimensions = dimensions\n",
    "        self.height = dimensions[\"height\"]\n",
    "        self.width = dimensions[\"width\"]\n",
    "        self.dataset_name = dataset_name\n",
    "        self.layers = layers\n",
    "        self.removed_layers = {'MIAMI_HC':4} # ONL layer\n",
    "        \n",
    "        self.metrics = None\n",
    "        self.overall_metrics = {k:[] for k in [\"IOU\",\"precision\",\"recall\",\"f1\"]}\n",
    "         \n",
    "        self.save_path = save_path\n",
    "        self.viz_path = os.path.join(self.save_path, 'visualisations_match', patient)\n",
    "        self.viz_path_overlay = os.path.join(self.save_path, 'visualisations_match_overlay', patient)\n",
    "        \n",
    "        \n",
    "        self.patient_eval_logs = []\n",
    "        self.patient_eval_stats = {k: {g:[] for g in ['precision','recall','IOU','f1']} for k in layers[dataset_name].keys()}\n",
    "        \n",
    "        Path(self.viz_path).mkdir(exist_ok=True, parents=True)\n",
    "        Path(self.viz_path_overlay).mkdir(exist_ok=True, parents=True)\n",
    "        \n",
    "    def saveViz(self, num, pred_rgb, gt_rgb, actual_img):\n",
    "        \n",
    "        cv2.imwrite('{}/Pred_{}_Slice_{}.png'.format(self.viz_path, self.patient, num), pred_rgb)\n",
    "        cv2.imwrite('{}/Ground_{}_Slice_{}.png'.format(self.viz_path, self.patient, num), gt_rgb)\n",
    "        cv2.imwrite('{}/Actual_{}_Slice_{}.png'.format(self.viz_path, self.patient, num), np.uint8(actual_img*255))\n",
    "    \n",
    "    def saveStack(self,pred_rgb_stack, gt_rgb_stack):\n",
    "        with h5py.File('{}/Stack_{}.hdf5'.format(self.viz_path,self.patient), 'w') as hf:\n",
    "            hf.create_dataset(\"pred\", data=pred_rgb_stack)\n",
    "            hf.create_dataset(\"gt\", data=gt_rgb_stack)\n",
    "        hf.close()        \n",
    "        \n",
    "    def layerMetrics(self, binary_img, gt_img, layer_name):\n",
    "        '''\n",
    "        layer based metrics after stitching up image\n",
    "        params: \n",
    "        binary_img: image of predicted segmentation for 1 layer\n",
    "        gt_img: image of ground truth segmentation for 1 layer\n",
    "        layer_name: layer name\n",
    "        \n",
    "        output:\n",
    "        patient_eval_stats: dictionary of all the patient-level metrics arranged by metric and layer name\n",
    "        metrics: all the metrics by metric type\n",
    "        '''\n",
    "        intersection = np.logical_and(gt_img, binary_img)\n",
    "        union = np.logical_or(gt_img, binary_img)\n",
    "        \n",
    "        tn, fp, fn, tp  = sklearn.metrics.confusion_matrix((gt_img).ravel()>0, (binary_img).ravel()).ravel()\n",
    "        IOU = np.sum(intersection) / np.sum(union)\n",
    "\n",
    "        def fxn():\n",
    "            warnings.warn(\"runtime\", RuntimeWarning)\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            fxn()\n",
    "            precision = tp/(tp+fp) # will lead to runtime warnings\n",
    "            \n",
    "        recall = tp/(tp+fn)\n",
    "        f1 = (2*tp)/((2*tp)+fp+fn)\n",
    "        \n",
    "        metric_names = ['precision', 'recall', 'IOU', 'f1']\n",
    "        metrics = [precision, recall, IOU, f1]\n",
    "        \n",
    "        for name, m in zip(metric_names, metrics):\n",
    "            self.patient_eval_stats[layer_name][name].append(m)\n",
    "            self.metrics[name].append(m)\n",
    "            \n",
    "\n",
    "    def getStats(self, patient_labels, patient_predictions, patient_images):\n",
    "        \n",
    "        # layer based matrics\n",
    "        pred_rgb_stack = np.zeros((*patient_images.shape, 3))\n",
    "        gt_rgb_stack = np.zeros((*patient_images.shape, 3))\n",
    "        \n",
    "        for num in range(patient_images.shape[0]):\n",
    "            bscan_label = patient_labels[num]\n",
    "            bscan_prediction = patient_predictions[num]\n",
    "            bscan_image = patient_images[num]\n",
    "            bscan_prediction[9] = bscan_prediction[0]+bscan_prediction[9]\n",
    "            bscan_label_max = np.argmax(bscan_label, axis=0)\n",
    "            bscan_prediction_max = np.argmax(bscan_prediction[1:], axis=0)\n",
    "\n",
    "            self.metrics = {k:[] for k in [\"IOU\",\"precision\",\"recall\",\"f1\"]}\n",
    "            # for visualisation purpose\n",
    "            pred_rgb = np.zeros((dimensions[\"height\"],dimensions[\"width\"], 3))\n",
    "            gt_rgb = np.zeros((dimensions[\"height\"],dimensions[\"width\"], 3))\n",
    "            \n",
    "            for idx2, (layer_name, color) in enumerate(self.layers[self.dataset_name].items()):\n",
    "                binary_img = (bscan_prediction_max == int(idx2))\n",
    "                gt_img = (bscan_label_max == int(idx2))\n",
    "                self.layerMetrics(binary_img, gt_img, layer_name)\n",
    "                pred_rgb[bscan_prediction_max==idx2] = color\n",
    "                gt_rgb[bscan_label_max==idx2] = color\n",
    "            \n",
    "\n",
    "            mean_precision, mean_recall, mean_iou, mean_f1 = tuple(map(lambda x: np.mean(self.metrics[x]),  \\\n",
    "                                                                 [\"precision\", \"recall\", \"IOU\", \"f1\"]))\n",
    "\n",
    "            pred_rgb_stack[idx] = pred_rgb\n",
    "            gt_rgb_stack[idx] = gt_rgb\n",
    "\n",
    "\n",
    "            # evaluation per b-scan\n",
    "            self.patient_eval_logs.append([self.patient, num, mean_iou, mean_precision, mean_recall, mean_f1])\n",
    "            self.saveViz(num, pred_rgb, gt_rgb, bscan_image)\n",
    "        self.saveStack(pred_rgb_stack, gt_rgb_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37591a70-453c-44fb-b16c-e835faba4aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(save_path, eval_stats, eval_logs, layers, dataset_name):\n",
    "    eval_logs = [stat for patient in eval_logs for stat in patient]\n",
    "\n",
    "    with open('{}/evaluation_stats.json'.format(save_path),'w') as fp:\n",
    "        json.dump(eval_stats, fp)\n",
    "\n",
    "    df = pd.DataFrame(eval_logs, columns = ['patient', 'scan', 'mean iou', 'mean precision', 'mean recall','mean f1'])\n",
    "    df['patient_no'] = df['patient'].astype(str).str.split('_').str[0].str.replace('0','').str[2:].astype(int)\n",
    "    df.sort_values(by=['patient_no'])\n",
    "    df.to_csv('{}/evaluation_logs.csv'.format(save_path), index=False)\n",
    "                \n",
    "    plt.figure(figsize=(20,10))\n",
    "    ax =  sns.boxplot(data = df, y = \"mean iou\", x = \"patient_no\", color = \"skyblue\", width=0.5)\n",
    "    [x.set_linewidth(4) for x in ax.spines.values()]\n",
    "    ax.set_xlabel(\"Patient Number\",fontsize=30, labelpad=10)\n",
    "    ax.set_ylabel(\"Mean IOU\",fontsize=30, labelpad=10)\n",
    "    plt.xticks(fontsize= 25)\n",
    "    plt.yticks(fontsize= 25)\n",
    "    plt.savefig(\"{}/iou.png\".format(save_path), dpi=300, bbox_inches='tight', transparent=True)\n",
    "    plt.close()\n",
    "\n",
    "    # layers\n",
    "    all_stats = []\n",
    "\n",
    "    # reordering to plot properly\n",
    "    new_eval_stats = {k: {g:[] for g in ['precision','recall','IOU','f1']} for k in layers[dataset_name].keys()}\n",
    "    # reformat the eval_stats dictionary\n",
    "    for layer in new_eval_stats.keys():\n",
    "        for metric in ['precision','recall','IOU','f1']:\n",
    "            new_eval_stats[layer][metric] = [num for p in eval_stats.keys() for num in eval_stats[p][layer][metric]]\n",
    "\n",
    "    for metric in ['IOU', 'precision', 'recall', 'f1']:\n",
    "        # append by layer\n",
    "        all_stats.append([new_eval_stats[k][metric] for k in new_eval_stats.keys()])\n",
    "\n",
    "    all_stats_name = ['IOU', 'Precision','Recall','F1 score']\n",
    "\n",
    "    for stat, name in zip(all_stats, all_stats_name): # plot by metric type\n",
    "        plt.figure(figsize=(20,10))\n",
    "        # plot box plot by layer\n",
    "        ax = sns.boxplot(data = [d for d in stat], color = \"skyblue\", width=0.5)\n",
    "#             sns.despine(offset=10, trim=True)\n",
    "        ax.set_xticklabels(new_eval_stats.keys())\n",
    "        [x.set_linewidth(4) for x in ax.spines.values()]\n",
    "#             ax.axes.set_title(\"Graph of mean {} across ground truth layers\".format(name),fontsize=40)\n",
    "        ax.set_xlabel(\"Layers\",fontsize=30, labelpad=10)\n",
    "        ax.set_ylabel(\"{}\".format(name),fontsize=30, labelpad=10)\n",
    "        plt.xticks(fontsize= 25)\n",
    "        plt.yticks(fontsize= 25)\n",
    "        plt.savefig(\"{}/{}_by_layer.png\".format(save_path, name), dpi=300, bbox_inches='tight', transparent=True)\n",
    "\n",
    "        plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "spectacular-simon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(raw_data_path, label_path, dimensions):\n",
    "    # for count,dataset in enumerate(image_datasets):\n",
    "    [header, BScanHeader, slo, BScans] = rd.octSpectralisReader(raw_data_path)\n",
    "    header['angle'] = 0\n",
    "\n",
    "    mat = scipy.io.loadmat(label_path)\n",
    "    annotations=mat['bd_pts']\n",
    "\n",
    "    background=np.ones(BScans.shape)\n",
    "    layers_map = np.zeros((annotations.shape[2], BScans.shape[0], BScans.shape[1], BScans.shape[2]))\n",
    "\n",
    "    for scan in range(annotations.shape[1]):\n",
    "        layers_map[:,:,:,scan] = build_mask(annotations[:,scan,:],dimensions['height'],dimensions['width'])\n",
    "    layers_map[layers_map.shape[0]-1]=background-np.sum(layers_map[:-1,:,:,:],0)\n",
    "    return layers_map, BScans\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "439addb9-2fc6-46a8-873d-489d2054f613",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImdbData(data.Dataset):\n",
    "    def __init__(self, X):\n",
    "        self.X = X\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.X[index]\n",
    "        img = torch.from_numpy(img)\n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "def getPredictions(BScans):\n",
    "    stitched_stack = np.zeros((dimensions['bscans'], \n",
    "                                    dimensions['layers'], dimensions['height'], dimensions['width']))\n",
    "    test_dataset = ImdbData(BScans)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "    for idx, (img) in enumerate(test_loader):\n",
    "        with torch.no_grad():\n",
    "            out = relaynet_model(Variable(img.cuda()))\n",
    "        out = F.softmax(out,dim=1)\n",
    "        \n",
    "        stitched_stack[idx] = np.squeeze(out.data.cpu().numpy())\n",
    "        \n",
    "    return stitched_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04fab965-b2b6-4f2f-ac0d-a1d17f6c058c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_predictions = []\n",
    "full_save_path = os.path.join(filepaths['project_dir'], filepaths['save_path'], filepaths['dataset_name'])\n",
    "Path(full_save_path).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "eval_logs = []\n",
    "for case in all_test_cases:  \n",
    "    patient = os.path.splitext(case)[0]\n",
    "    \n",
    "    eval_patient = EvalPatient(patient, dimensions, filepaths['dataset_name'], layers, full_save_path)\n",
    "    \n",
    "    \n",
    "    raw_data_path = os.path.join(filepaths['project_dir'],'data','raw',filepaths['dataset_name'], patient+'.vol')\n",
    "    label_path=os.path.join(filepaths['project_dir'],'data','labels', filepaths['dataset_name'],patient+'_label.mat')\n",
    "    \n",
    "    \n",
    "    layers_map, BScans = prepare_dataset(raw_data_path, label_path, dimensions)\n",
    "    BScans2 = np.expand_dims(np.transpose(BScans, (2, 0, 1)), axis = 1)\n",
    "    stitched_stack = getPredictions(BScans2)\n",
    "    layers_map2 = np.transpose(layers_map, (3, 0, 1, 2))\n",
    "    BScans2 = np.squeeze(BScans2, axis=1)\n",
    "    \n",
    "    eval_patient.getStats(layers_map2, stitched_stack, BScans2)\n",
    "    \n",
    "    eval_logs.append(eval_patient.patient_eval_logs)\n",
    "    eval_stats[patient] = eval_patient.patient_eval_stats\n",
    "            \n",
    "    all_predictions.append(stitched_stack)\n",
    "    \n",
    "plot_result(full_save_path, eval_stats, eval_logs, layers, filepaths['dataset_name'])\n",
    "with h5py.File(os.path.join(filepaths['predictions'],'predictions'+'.hdf5'), 'w') as hf:\n",
    "    hf.create_dataset('pred', data=all_predictions)\n",
    "hf.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
