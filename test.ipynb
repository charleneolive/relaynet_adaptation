{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "attended-afghanistan",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "activated-protein",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import scipy\n",
    "import scipy.io\n",
    "import cv2\n",
    "import h5py\n",
    "import yaml\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from preprocess.data_prep_utils import retinaFlatten as rf\n",
    "from preprocess.data_prep_utils import octSpectralisReader as rd\n",
    "from preprocess.data_prep_utils.misc import build_mask\n",
    "from networks.data_utils import ImdbData\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable \n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "SEG_LABELS_LIST = [\n",
    "    {\"id\": -1, \"name\": \"void\", \"rgb_values\": [0, 0, 0]},\n",
    "    {\"id\": 0, \"name\": \"Region above the retina (RaR)\", \"rgb_values\": [128, 0, 0]},\n",
    "    {\"id\": 1, \"name\": \"ILM: Inner limiting membrane\", \"rgb_values\": [0, 128, 0]},\n",
    "    {\"id\": 2, \"name\": \"NFL-IPL: Nerve fiber ending to Inner plexiform layer\", \"rgb_values\": [128, 128, 0]},\n",
    "    {\"id\": 3, \"name\": \"INL: Inner Nuclear layer\", \"rgb_values\": [0, 0, 128]},\n",
    "    {\"id\": 4, \"name\": \"OPL: Outer plexiform layer\", \"rgb_values\": [128, 0, 128]},\n",
    "    {\"id\": 5, \"name\": \"ONL-ISM: Outer Nuclear layer to Inner segment myeloid\", \"rgb_values\": [0, 128, 128]},\n",
    "    {\"id\": 6, \"name\": \"ISE: Inner segment ellipsoid\", \"rgb_values\": [128, 128, 128]},\n",
    "    {\"id\": 7, \"name\": \"OS-RPE: Outer segment to Retinal pigment epithelium\", \"rgb_values\": [64, 0, 0]},\n",
    "    {\"id\": 8, \"name\": \"Region below RPE (RbR)\", \"rgb_values\": [192, 0, 0]}];\n",
    "    #{\"id\": 9, \"name\": \"Fluid region\", \"rgb_values\": [64, 128, 0]}];\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "spectacular-simon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(raw_data_path, label_path):\n",
    "    # for count,dataset in enumerate(image_datasets):\n",
    "    [header, BScanHeader, slo, BScans] = rd.octSpectralisReader(raw_data_path)\n",
    "    header['angle'] = 0\n",
    "\n",
    "    mat = scipy.io.loadmat(label_path)\n",
    "    annotations=mat['bd_pts']\n",
    "\n",
    "    background=np.ones(BScans.shape)\n",
    "    layers_map = np.zeros((annotations.shape[2], BScans.shape[0], BScans.shape[1], BScans.shape[2]))\n",
    "\n",
    "    for scan in range(annotations.shape[1]):\n",
    "        layers_map[:,:,:,scan] = build_mask(annotations[:,scan,:],height,width)\n",
    "    layers_map[layers_map.shape[0]-1]=background-np.sum(layers_map[:-1,:,:,:],0)\n",
    "    return layers_map, BScans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "elder-geology",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_img_to_rgb(label_img):\n",
    "\n",
    "    label_img = np.squeeze(label_img)\n",
    "    labels = np.unique(label_img)\n",
    "    label_infos = [l for l in SEG_LABELS_LIST if l['id'] in labels]\n",
    "\n",
    "    label_img_rgb = np.array([label_img,\n",
    "                              label_img,\n",
    "                              label_img]).transpose(1,2,0)\n",
    "    for l in label_infos:\n",
    "        mask = label_img == l['id']\n",
    "        label_img_rgb[mask] = l['rgb_values']\n",
    "\n",
    "    return label_img_rgb.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "outdoor-firewall",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open( \"./test.yaml\") as file:\n",
    "    config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "data_dir = config['filepaths']['data_dir']\n",
    "dataset_name = config['filepaths']['dataset_name']\n",
    "save_path = config['filepaths']['save_path']\n",
    "test_dataset = os.path.join(data_dir,'processed', dataset_name, config['filepaths']['test_dataset'])\n",
    "height = config['general']['height']\n",
    "width = config['general']['width']\n",
    "layers = config['general']['layers']\n",
    "\n",
    "relaynet_model =  torch.load(config['filepaths']['model_path'])\n",
    "relaynet_model.eval()\n",
    "\n",
    "all_test_cases = []\n",
    "with open(test_dataset,'r') as reader:\n",
    "    for idx, line in enumerate(reader.readlines()):\n",
    "        all_test_cases.append(line.strip('\\n'))\n",
    "predicted_segmentations = np.zeros((len(all_test_cases), 49, layers, height, width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04fab965-b2b6-4f2f-ac0d-a1d17f6c058c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(496, 1024, 49)\n",
      "(1024, 49, 9)\n",
      "(496, 1024, 49)\n",
      "(1024, 49, 9)\n",
      "(496, 1024, 49)\n",
      "(1024, 49, 9)\n"
     ]
    }
   ],
   "source": [
    "for case in all_test_cases:  \n",
    "    patient_name = os.path.splitext(case)[0]\n",
    "    raw_data_path = os.path.join(data_dir,'raw', dataset_name, patient_name+'.vol')\n",
    "    label_path=os.path.join(data_dir,'labels', dataset_name,patient_name+'_label.mat')\n",
    "    \n",
    "    layers_map, BScans = prepare_dataset(raw_data_path, label_path)\n",
    "    BScans2 = np.expand_dims(np.transpose(BScans, (2, 0, 1)), axis = 1)\n",
    "    layers_map2 = np.transpose(layers_map, (3, 0, 1, 2))\n",
    "\n",
    "    test_dataset = ImdbData(BScans2, layers_map2)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    for idx2, (img, label) in enumerate(test_loader):\n",
    "        with torch.no_grad():\n",
    "            out = relaynet_model(Variable(img.cuda()))\n",
    "\n",
    "        out = F.softmax(out,dim=1)\n",
    "        predicted_segmentations[idx, idx2] = np.squeeze(out.data.cpu().numpy())\n",
    "        max_val, rgb_img = torch.max(out,1)\n",
    "        rgb_img = rgb_img.data.cpu().numpy()\n",
    "        rgb_img = label_img_to_rgb(rgb_img[0])\n",
    "\n",
    "        Path(os.path.join(save_path, patient_name)).mkdir(parents=True, exist_ok = True)\n",
    "        cv2.imwrite(os.path.join(save_path, patient_name, \"scan\"+str(idx2)+\".png\"), rgb_img)\n",
    "            \n",
    "with h5py.File(os.path.join(save_path,'predictions'+'.hdf5'), 'w') as hf:\n",
    "    hf.create_dataset('predictions', data=predicted_segmentations)\n",
    "hf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-messenger",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
