{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "under-belly",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mounted-evanescence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "from networks.data_utils import get_imdb_data\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "from networks.relay_net import ReLayNet\n",
    "# from networks.solver import Solver\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "married-kinase",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomTransforms(object):\n",
    "    def __init__(self, height, width, layers, prob1=1, prob2=0.5, border = [8,8,8,8]):\n",
    "        # tblr\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.layers = layers\n",
    "        self.prob1 = prob1\n",
    "        self.prob2 = prob2\n",
    "        self.b = border\n",
    "\n",
    "    def __call__(self, image, target, weight):\n",
    "\n",
    "        if random.random()<self.prob1:\n",
    "            pad_image = np.zeros((self.height+self.b[0]+self.b[1], self.width+self.b[2]+self.b[3], 1))\n",
    "            pad_target = np.zeros((self.height+self.b[0]+self.b[1], self.width+self.b[2]+self.b[3], self.layers))\n",
    "            pad_weight = np.zeros((self.height+self.b[0]+self.b[1], self.width+self.b[2]+self.b[3]))\n",
    "            \n",
    "            # mirror image\n",
    "            pad_image[self.b[0]:-self.b[1],self.b[2]:-self.b[3],:] = image \n",
    "            pad_image[:self.b[0],self.b[2]:-self.b[3]] = image[self.b[0]-1:None:-1]# fill up top border\n",
    "            pad_image[-self.b[1]:,self.b[2]:-self.b[3]] = image[:-self.b[1]-1:-1] # fill up bottom border\n",
    "            pad_image[:,self.b[2]-1:None:-1] = pad_image[:,self.b[2]:2*self.b[2]] # fill up left border\n",
    "            pad_image[:,-self.b[3]:] = pad_image[:,-self.b[3]-1:-2*self.b[3]-1:-1] # fill up right border\n",
    "\n",
    "            # mirror target\n",
    "            pad_target[self.b[0]:-self.b[1],self.b[2]:-self.b[3],:] = target \n",
    "            pad_target[:self.b[0],self.b[2]:-self.b[3]] = target[self.b[0]-1:None:-1]# fill up top border\n",
    "            pad_target[-self.b[1]:,self.b[2]:-self.b[3]] = target[:-self.b[1]-1:-1] # fill up bottom border\n",
    "            pad_target[:,self.b[2]-1:None:-1] = pad_target[:,self.b[2]:2*self.b[2]] # fill up left border\n",
    "            pad_target[:,-self.b[3]:] = pad_target[:,-self.b[3]-1:-2*self.b[3]-1:-1] # fill up right border\n",
    "\n",
    "            # mirror weight\n",
    "            pad_weight[self.b[0]:-self.b[1],self.b[2]:-self.b[3]] = weight \n",
    "            pad_weight[:self.b[0],self.b[2]:-self.b[3]] = weight[self.b[0]-1:None:-1]# fill up top border\n",
    "            pad_weight[-self.b[1]:,self.b[2]:-self.b[3]] = weight[:-self.b[1]-1:-1] # fill up bottom border\n",
    "            pad_weight[:,self.b[2]-1:None:-1] = pad_weight[:,self.b[2]:2*self.b[2]] # fill up left border\n",
    "            pad_weight[:,-self.b[3]:] = pad_weight[:,-self.b[3]-1:-2*self.b[3]-1:-1] # fill up right border\n",
    "\n",
    "            loc = [randint(0,16-1), randint(0,16-1)]\n",
    "            image = pad_image[loc[0]:loc[0]+self.height, loc[1]:loc[1]+self.width]\n",
    "            target = pad_target[loc[0]:loc[0]+self.height, loc[1]:loc[1]+self.width]\n",
    "            weight = pad_weight[loc[0]:loc[0]+self.height, loc[1]:loc[1]+self.width]\n",
    "        \n",
    "        if random.random() < self.prob2:\n",
    "            '''\n",
    "            flipping\n",
    "            '''\n",
    "\n",
    "            image = np.flip(image,1)\n",
    "            target = np.flip(target,1)\n",
    "            weight = np.flip(weight,1)\n",
    "        return image, target, weight\n",
    "                \n",
    "class ImdbData(Dataset):\n",
    "    \n",
    "    def __init__(self, config, X, y, W, transform=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.w = W\n",
    "        self.height = config['general']['HEIGHT']\n",
    "        self.width = config['general']['WIDTH']\n",
    "        self.layers = config['general']['layers']\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = np.transpose(self.X[index], (1,2,0)) \n",
    "        label = np.transpose(self.y[index],(1,2,0))\n",
    "        weight = self.w[index]\n",
    "        if self.transform is not None:\n",
    "            img, label, weight = self.transform(img, label, weight)\n",
    "\n",
    "        img = torch.from_numpy(img.copy()).float().permute(2,0,1)\n",
    "        label = torch.from_numpy(label.copy()).long().permute(2,0,1)\n",
    "        weight = torch.from_numpy(weight.copy()).float()\n",
    "    \n",
    "        return img, label, weight\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "gorgeous-reading",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open( \"./train.yaml\") as file:\n",
    "    config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "HEIGHT = config['general']['HEIGHT']\n",
    "WIDTH = config['general']['WIDTH']\n",
    "layers = config['general']['layers']\n",
    "exp_dir_name = config['filepaths']['exp_dir_name']\n",
    "\n",
    "model_path = config['filepaths']['model_path']\n",
    "data_dir = config['filepaths']['processed_data_path']\n",
    "param = config['param']\n",
    "\n",
    "train_images, train_labels, train_wmaps, val_images, val_labels, val_wmaps = get_imdb_data(data_dir)\n",
    "\n",
    "train_images2 = np.copy(np.expand_dims(train_images.reshape(-1,HEIGHT, WIDTH), axis = 1))\n",
    "train_labels2 = np.copy(train_labels.reshape(-1, layers, HEIGHT, WIDTH))\n",
    "train_wmaps2 = np.copy(train_wmaps.reshape(-1, HEIGHT, WIDTH))\n",
    "\n",
    "val_images2 = np.copy(np.expand_dims(val_images.reshape(-1,HEIGHT, WIDTH), axis = 1))\n",
    "val_labels2 = np.copy(val_labels.reshape(-1, layers, HEIGHT, WIDTH))\n",
    "val_wmaps2 = np.copy(val_wmaps.reshape(-1, HEIGHT, WIDTH))\n",
    "\n",
    "# combining train and validation since paper only did train\n",
    "train_images3 = np.concatenate((train_images2, val_images2), axis=0)\n",
    "train_labels3 = np.concatenate((train_labels2, val_labels2), axis=0)\n",
    "train_wmaps3 = np.concatenate((train_wmaps2, val_wmaps2), axis=0)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8aeaf5b2-d860-4e7f-87b1-bd2a70afcf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import pathlib\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from torch.nn.modules.loss import _Loss\n",
    "from torch.autograd import Function, Variable\n",
    "from torch.autograd import Variable\n",
    "from networks.net_api.losses import DiceLoss, CrossEntropyLoss2d\n",
    "from torch.optim import lr_scheduler\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class Solver(object):\n",
    "    # global optimiser parameters\n",
    "    default_optim_args = {\"lr\": 0.1,\n",
    "                          \"momentum\" : 0.9,\n",
    "                          \"weight_decay\": 0.0001}\n",
    "    gamma = 0.1\n",
    "    step_size = 30\n",
    "    NumClass = 10 # TO CHANGE\n",
    "\n",
    "    def __init__(self, device, optim=torch.optim.SGD, optim_args={}):\n",
    "        optim_args_merged = self.default_optim_args.copy()\n",
    "        optim_args_merged.update(optim_args)\n",
    "        self.optim_args = optim_args_merged\n",
    "        self.optim = optim\n",
    "        self.loss_func = CombinedLoss(device)\n",
    "        self.device = device\n",
    "\n",
    "        self._reset_histories()\n",
    "\n",
    "    def _reset_histories(self):\n",
    "        \"\"\"\n",
    "        Resets train and val histories for the accuracy and the loss.\n",
    "        \"\"\"\n",
    "        self.train_loss_history = []\n",
    "        self.train_acc_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "centered-windows",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_transform = RandomTransforms(config['general']['HEIGHT'], config['general']['WIDTH'], config['general']['layers'])\n",
    "\n",
    "train_dataset = ImdbData(config, train_images3, train_labels3, train_wmaps3, transform = random_transform)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1bd031-7f8e-4af2-af3f-8e636bd78b75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776f1006-3fb8-46d0-bd13-2967f8c68f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=50, shuffle=True, num_workers=4)\n",
    "# val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=50, shuffle=False, num_workers=4)\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "relaynet_model = ReLayNet(param)\n",
    "solver = Solver(device)\n",
    "num_epochs = 60\n",
    "        \n",
    "# solver.train(relaynet_model, train_loader, model_path=model_path, num_epochs=num_epochs, log_nth=1,  exp_dir_name=exp_dir_name)\n",
    "\n",
    "model = relaynet_model\n",
    "log_nth = 1\n",
    "exp_dir_name = 'exp_default'\n",
    "\n",
    "\"\"\"\n",
    "Train a given model with the provided data.\n",
    "\n",
    "Inputs:\n",
    "- model: model object initialized from a torch.nn.Module\n",
    "- train_loader: train data in torch.utils.data.DataLoader\n",
    "- num_epochs: total number of training epochs\n",
    "- log_nth: log training accuracy and loss every nth iteration\n",
    "\"\"\"\n",
    "optim = solver.optim(model.parameters(), **solver.optim_args)\n",
    "# learning rate schedular\n",
    "scheduler = lr_scheduler.StepLR(optim, step_size=solver.step_size,\n",
    "                                gamma=solver.gamma)  # decay LR by a factor of 0.1 every 30 epochs\n",
    "\n",
    "\n",
    "iter_per_epoch = 1\n",
    "# iter_per_epoch = len(train_loader)\n",
    "\n",
    "model.to(solver.device)\n",
    "\n",
    "print('START TRAIN.')\n",
    "curr_iter = 0\n",
    "\n",
    "per_epoch_train_acc = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    scheduler.step()\n",
    "    solver._reset_histories()\n",
    "    model.train()\n",
    "    iteration = 0\n",
    "\n",
    "    batch = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "\n",
    "    for i_batch, sample_batched in batch:\n",
    "        X = Variable(sample_batched[0], requires_grad=True)\n",
    "        y = Variable(sample_batched[1])\n",
    "        w = Variable(sample_batched[2])\n",
    "\n",
    "        if model.is_cuda:\n",
    "            X, y, w = X.cuda(), y.cuda(), w.cuda()\n",
    "        optim.zero_grad()\n",
    "        output = model(X)\n",
    "        loss = solver.loss_func(output, y, w)\n",
    "\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        _,batch_output =torch.max(F.softmax(output, dim=1), dim=1)\n",
    "        _, y = torch.max(y, dim=1)\n",
    "\n",
    "        avg_dice = per_class_dice(batch_output, y, solver.NumClass)\n",
    "        solver.train_loss_history.append(loss.detach().item())\n",
    "\n",
    "        solver.train_acc_history.append(avg_dice)\n",
    "    per_epoch_train_acc.append(np.sum(np.asarray(solver.train_acc_history))/len(train_loader))\n",
    "\n",
    "    print('[Epoch : {} / {}]: {:.2f}'.format(epoch, num_epochs, avg_dice.item()))\n",
    "\n",
    "    full_save_path = os.path.join(model_path, exp_dir_name)\n",
    "    pathlib.Path(full_save_path).mkdir(parents=True, exist_ok=True)\n",
    "    model.save(os.path.join(full_save_path, 'relaynet_epoch'+ str(epoch + 1) + '.model'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f913aa0-6dc8-434a-9623-e1b6f60e5ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_class_dice(y_pred, y_true, num_class):\n",
    "    avg_dice = 0\n",
    "    y_pred = y_pred.data.cpu().numpy()\n",
    "    y_true = y_true.data.cpu().numpy()\n",
    "    for i in range(5,num_class):\n",
    "        GT = y_true == (i)\n",
    "        Pred = y_pred == (i)\n",
    "        plt.figure()\n",
    "        plt.imshow(GT[0])\n",
    "        plt.figure()\n",
    "        plt.imshow(Pred[0])\n",
    "        inter = np.sum(np.multiply(GT, Pred)) + 0.0001\n",
    "        union = np.sum(GT) + np.sum(Pred) + 0.0001\n",
    "        t = 2 * inter / union\n",
    "        print(t)\n",
    "        avg_dice = avg_dice + (t / num_class)\n",
    "        break\n",
    "    return avg_dice\n",
    "\n",
    "per_class_dice(batch_output, y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bb578f-0d92-42f1-babc-89a2d3d66b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=d)\n",
    "df.to_csv(os.path.join(full_save_path, 'accuracy_history.csv'))\n",
    "print('FINISH.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
